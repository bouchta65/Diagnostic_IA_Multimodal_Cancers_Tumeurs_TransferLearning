{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b408217",
   "metadata": {},
   "source": [
    "# Chargement du modèle GoogLeNet pré-entraîné\n",
    "\n",
    " charge le modèle **GoogLeNet** pré-entraîné sur le dataset ImageNet, en utilisant la bibliothèque PyTorch.\n",
    "\n",
    "### Imports nécessaires\n",
    "\n",
    "- **`torch`** : Bibliothèque principale de PyTorch pour le deep learning\n",
    "- **`torch.nn`** : Module contenant les composants pour construire des réseaux de neurones\n",
    "- **`torchvision.models`** : Module contenant des architectures de modèles pré-entraînés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bb9ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.googlenet(pretrained=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e4f34",
   "metadata": {},
   "source": [
    "# Gel des paramètres d'un modèle\n",
    "Ce code **gèle tous les paramètres** d'un modèle de réseau de neurones, empêchant leur mise à jour pendant l'entraînement.\n",
    "Cette boucle parcourt **tous les paramètres** (poids et biais) du modèle et désactive le calcul des gradients pour chacun d'eux.\n",
    "\n",
    "\n",
    "```python\n",
    "    param.requires_grad = False\n",
    "```\n",
    "- `requires_grad` : Attribut qui indique si PyTorch doit calculer les gradients\n",
    "- ` False` : Désactive le calcul des gradients pour ce paramètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfd8651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdec59",
   "metadata": {},
   "source": [
    "# Remplacement du classificateur par un réseau personnalisé\n",
    "\n",
    "## Description de la tâche\n",
    "\n",
    " **remplace la couche de classification finale** d'un modèle pré-entraîné (GoogLeNet) par un **réseau de neurones personnalisé** à plusieurs couches pour classifier 4 classes.\n",
    "\n",
    " crée un **classificateur multi-couches** pour adapter GoogLeNet à une tâche de classification à 4 classes.\n",
    "#### 1. Définir le nombre de classes cibles\n",
    "\n",
    "```python\n",
    "num_classes = 4\n",
    "```\n",
    "- Nombre de catégories à prédire (par exemple : chien, chat, oiseau, poisson)\n",
    "\n",
    "#### 2. Remplacer la couche finale\n",
    "\n",
    "```python\n",
    "model.fc = nn.Sequential(...)\n",
    "```\n",
    "- `model.fc` : La couche \"fully connected\" (dense) finale de GoogLeNet\n",
    "- `nn.Sequential` : Conteneur qui empile plusieurs couches en séquence\n",
    "\n",
    "#### 3. Architecture du nouveau classificateur\n",
    "\n",
    "```python\n",
    "nn.Linear(1024, 256)\n",
    "```\n",
    "- **Couche dense 1** : Transforme les 1024 features de GoogLeNet en 256 neurones\n",
    "- `1024` : Dimension de sortie de GoogLeNet (features extraites)\n",
    "- `256` : Nombre de neurones dans la couche cachée\n",
    "\n",
    "```python\n",
    "nn.ReLU()\n",
    "```\n",
    "- **Fonction d'activation** : Rectified Linear Unit\n",
    "- Introduit la non-linéarité : `f(x) = max(0, x)`\n",
    "- Permet au réseau d'apprendre des relations complexes\n",
    "\n",
    "```python\n",
    "nn.Dropout(0.5)\n",
    "```\n",
    "- **Régularisation** : Désactive aléatoirement 50% des neurones pendant l'entraînement\n",
    "- Prévient le sur-apprentissage (overfitting)\n",
    "- Rend le modèle plus robuste\n",
    "\n",
    "```python\n",
    "nn.Linear(256, num_classes)\n",
    "```\n",
    "- **Couche dense 2** : Transforme les 256 neurones en 4 sorties (une par classe)\n",
    "- Produit les scores bruts (logits) pour chaque classe\n",
    "\n",
    "```python\n",
    "nn.Softmax(dim=1)\n",
    "```\n",
    "- **Fonction d'activation finale** : Convertit les logits en probabilités\n",
    "- `dim=1` : Applique softmax sur la dimension des classes\n",
    "- Résultat : Somme des probabilités = 1.0\n",
    "\n",
    "## Architecture visuelle\n",
    "\n",
    "```\n",
    "Features GoogLeNet (1024) \n",
    "          ↓\n",
    "    Linear (1024 → 256)\n",
    "          ↓\n",
    "       ReLU()\n",
    "          ↓\n",
    "    Dropout(50%)\n",
    "          ↓\n",
    "    Linear (256 → 4)\n",
    "          ↓\n",
    "    Softmax(dim=1)\n",
    "          ↓\n",
    "  Probabilités [0.1, 0.6, 0.2, 0.1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f86fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "# print(len(train_dataset.classes))\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(1024, 256), \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b62e8400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogLeNet(\n",
      "  (conv1): BasicConv2d(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): BasicConv2d(\n",
      "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception3a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception3b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception4a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4c): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4d): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4e): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception5a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception5b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (aux1): None\n",
      "  (aux2): None\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=4, bias=True)\n",
      "    (4): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3fc4c",
   "metadata": {},
   "source": [
    "# Configuration de l'entraînement du modèle\n",
    "\n",
    "\n",
    "### 1. Learning Rate (Taux d'apprentissage)\n",
    "\n",
    "```python\n",
    "learning_rate = 0.001\n",
    "```\n",
    "\n",
    "- **Définition** : Contrôle la taille des pas lors de la mise à jour des poids\n",
    "\n",
    "### 2. Loss Function (Fonction de perte)\n",
    "- **Fonction** : Mesure l'erreur entre les prédictions et les vraies classes\n",
    "- **CrossEntropyLoss** : Combinaison de Softmax + Negative Log Likelihood\n",
    "- **Utilisation** : Classification multi-classes\n",
    "\n",
    "### 3. Optimizer (Optimiseur)\n",
    "\n",
    "```python\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "```\n",
    "\n",
    "- **Adam** : Optimiseur adaptatif performant (combine momentum et RMSprop)\n",
    "- **`model.fc.parameters()`** : Entraîne **uniquement** les nouvelles couches (le classificateur)\n",
    "- **`lr=learning_rate`** : Applique le taux d'apprentissage défini\n",
    "\n",
    "### Autres optimiseurs\n",
    "\n",
    "```python\n",
    "# SGD (plus simple, nécessite plus de réglages)\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# AdamW (Adam avec weight decay)\n",
    "optimizer = optim.AdamW(model.fc.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# RMSprop\n",
    "optimizer = optim.RMSprop(model.fc.parameters(), lr=0.001)\n",
    "```\n",
    "### Autres loss functions\n",
    "\n",
    "```python\n",
    "# Pour classification binaire\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Pour régression\n",
    "loss_function = nn.MSELoss()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e22cb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determiner le learning rate et loss function et aussi l’optomizer pour le modele\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# print(device)\n",
    "learning_rate  = 0.001   \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0bbf23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5204\n",
      "1105\n",
      "1108\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = torch.load(\"../data/Data_Loaders/train_dataset.pt\", weights_only=False)\n",
    "val_dataset   = torch.load(\"../data/Data_Loaders/val_dataset.pt\", weights_only=False)\n",
    "test_dataset  = torch.load(\"../data/Data_Loaders/test_dataset.pt\", weights_only=False)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d2978bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 1.0193, Accuracy: 74.33%\n",
      "Epoch 2/5 - Loss: 0.8458, Accuracy: 90.97%\n",
      "Epoch 3/5 - Loss: 0.8193, Accuracy: 93.27%\n",
      "Epoch 4/5 - Loss: 0.8076, Accuracy: 94.16%\n",
      "Epoch 5/5 - Loss: 0.8031, Accuracy: 94.64%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd07376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Loss = 0.7670, Accuracy = 97.92%\n",
      "Test       : Loss = 0.7634, Accuracy = 98.38%\n",
      "train       : Loss = 0.7693, Accuracy = 97.77%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "val_loss, val_acc = evaluate(model, val_loader, loss_function)\n",
    "test_loss, test_acc = evaluate(model, test_loader, loss_function)\n",
    "train_loss,train_acc=evaluate(model,train_loader,loss_function)\n",
    "\n",
    "print(f\"Validation : Loss = {val_loss:.4f}, Accuracy = {val_acc:.2f}%\")\n",
    "print(f\"Test       : Loss = {test_loss:.4f}, Accuracy = {test_acc:.2f}%\")\n",
    "print(f\"train       : Loss = {train_loss:.4f}, Accuracy = {train_acc:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
